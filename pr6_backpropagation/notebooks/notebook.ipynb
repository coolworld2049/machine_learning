{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras import Model\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/diabetes.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    print(\"Before preprocessing\")\n",
    "    print(\"Number of rows with 0 values\")\n",
    "    for col in df.columns:\n",
    "        missing_rows = df.loc[df[col] == 0].shape[0]\n",
    "        print(col + \": \" + str(missing_rows))\n",
    "\n",
    "    # Replace 0 values with the mean of the existing values\n",
    "    df[\"Glucose\"] = df[\"Glucose\"].replace(0, np.nan)\n",
    "    df[\"BloodPressure\"] = df[\"BloodPressure\"].replace(0, np.nan)\n",
    "    df[\"SkinThickness\"] = df[\"SkinThickness\"].replace(0, np.nan)\n",
    "    df[\"Insulin\"] = df[\"Insulin\"].replace(0, np.nan)\n",
    "    df[\"BMI\"] = df[\"BMI\"].replace(0, np.nan)\n",
    "    df[\"Glucose\"] = df[\"Glucose\"].fillna(df[\"Glucose\"].mean())\n",
    "    df[\"BloodPressure\"] = df[\"BloodPressure\"].fillna(df[\"BloodPressure\"].mean())\n",
    "    df[\"SkinThickness\"] = df[\"SkinThickness\"].fillna(df[\"SkinThickness\"].mean())\n",
    "    df[\"Insulin\"] = df[\"Insulin\"].fillna(df[\"Insulin\"].mean())\n",
    "    df[\"BMI\"] = df[\"BMI\"].fillna(df[\"BMI\"].mean())\n",
    "\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(\"After preprocessing\")\n",
    "    print(\"Number of rows with 0 values\")\n",
    "    for col in df.columns:\n",
    "        missing_rows = df.loc[df[col] == 0].shape[0]\n",
    "        print(col + \": \" + str(missing_rows))\n",
    "\n",
    "    # Standardization\n",
    "    df_scaled = preprocessing.scale(df)\n",
    "    df_scaled = pd.DataFrame(df_scaled, columns=df.columns)\n",
    "    df_scaled[\"Outcome\"] = df[\"Outcome\"]\n",
    "    df = df_scaled\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df = preprocess(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(8, 6))\n",
    "sns.heatmap(df.corr(), annot=True, ax=ax)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.countplot(x=df.Outcome)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "column_names = df.columns\n",
    "column_names = column_names.drop(\"Outcome\")\n",
    "for name in column_names:\n",
    "    print(\"{}\\n\".format(name))\n",
    "    print(df.groupby([\"Outcome\"])[name].mean())\n",
    "    print(\"*\" * 50)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.hist()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multilayer perceptron"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:8]\n",
    "y = df.iloc[:, 8]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# np.random.seed(5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.activations import hard_sigmoid  # noqa\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD  # noqa\n",
    "\n",
    "\n",
    "# model.add(Dense(10, input_dim=8, activation='relu'))\n",
    "# model.add(Dense(50, activation='relu'))\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "# model.add(Dense(5, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, kernel_initializer=\"uniform\", input_dim=8, activation=\"relu\"))\n",
    "    model.add(Dense(50, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
    "    model.add(Dense(10, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
    "    model.add(Dense(5, kernel_initializer=\"uniform\", activation=\"relu\"))\n",
    "    model.add(Dense(1, kernel_initializer=\"uniform\", activation=\"sigmoid\"))\n",
    "    sgd = SGD(learning_rate=1 / len(df), momentum=0.9, decay=0.0, nesterov=False)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_1 = create_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_1.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_model(model: Model):\n",
    "    m = model\n",
    "    scores = m.evaluate(X, y)\n",
    "    print(\"\\n%s: %.2f%%\" % (model_1.metrics_names[1], scores[1] * 100))\n",
    "\n",
    "\n",
    "def evaluate_model_train_test(model: Model):\n",
    "    scores = model.evaluate(X_train, y_train, verbose=False)\n",
    "    print(\"Training Accuracy: %.2f%%\" % (scores[1] * 100))\n",
    "    scores = model.evaluate(X_test, y_test, verbose=False)\n",
    "    print(\"Testing Accuracy: %.2f%%\" % (scores[1] * 100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_hist_1a = model_1.fit(\n",
    "    X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=10\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate_model(model_1)\n",
    "evaluate_model_train_test(model_1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig_run_hist_1a, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.plot(run_hist_1a.history[\"loss\"], \"r\", marker=\".\", label=\"Train Loss\")\n",
    "ax.plot(run_hist_1a.history[\"val_loss\"], \"b\", marker=\".\", label=\"Validation Loss\")\n",
    "ax.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "run_hist_1b = model_1.fit(\n",
    "    X_train, y_train, validation_data=(X_test, y_test), epochs=1000, batch_size=10\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate_model(model_1)\n",
    "evaluate_model_train_test(model_1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def msa_plot():\n",
    "    n_loss = len(run_hist_1a.history[\"loss\"])\n",
    "    m_loss = len(run_hist_1b.history[\"loss\"])\n",
    "    fig_msa = make_subplots(rows=1, cols=1)\n",
    "    run_hist_1a_traces_msa = [\n",
    "        go.Scatter(\n",
    "            x=np.arange(n_loss), y=run_hist_1a.history[\"loss\"], name=\"loss - Run 1\"\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=np.arange(n_loss),\n",
    "            y=run_hist_1a.history[\"val_loss\"],\n",
    "            name=\"val_loss - Run 1\",\n",
    "        ),\n",
    "    ]\n",
    "    run_hist_1b_traces_msa = [\n",
    "        go.Scatter(\n",
    "            x=np.arange(n_loss, n_loss + m_loss),\n",
    "            y=run_hist_1b.history[\"loss\"],\n",
    "            name=\"loss - Run 2\",\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=np.arange(n_loss, n_loss + m_loss),\n",
    "            y=run_hist_1b.history[\"val_loss\"],\n",
    "            name=\"val_loss - Run 2\",\n",
    "        ),\n",
    "    ]\n",
    "    fig_msa.add_traces([*run_hist_1a_traces_msa, *run_hist_1b_traces_msa])\n",
    "    fig_msa.show()\n",
    "\n",
    "\n",
    "def mse_plot():\n",
    "    n_mse = len(run_hist_1a.history[\"mean_squared_error\"])\n",
    "    m_mse = len(run_hist_1b.history[\"mean_squared_error\"])\n",
    "    fig_mse = make_subplots(rows=2, cols=1)\n",
    "    run_hist_1a_traces_mse = [\n",
    "        go.Scatter(\n",
    "            x=np.arange(n_mse),\n",
    "            y=run_hist_1a.history[\"mean_squared_error\"],\n",
    "            name=\"mean_squared_error - Run 1\",\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=np.arange(n_mse),\n",
    "            y=run_hist_1a.history[\"val_mean_squared_error\"],\n",
    "            name=\"val_mean_squared_error - Run 1\",\n",
    "        ),\n",
    "    ]\n",
    "    run_hist_1b_traces_mse = [\n",
    "        go.Scatter(\n",
    "            x=np.arange(n_mse, n_mse + m_mse),\n",
    "            y=run_hist_1b.history[\"mean_squared_error\"],\n",
    "            name=\"mean_squared_error - Run 2\",\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=np.arange(n_mse, n_mse + m_mse),\n",
    "            y=run_hist_1b.history[\"val_mean_squared_error\"],\n",
    "            name=\"val_mean_squared_error - Run 2\",\n",
    "        ),\n",
    "    ]\n",
    "    fig_mse.add_traces(run_hist_1a_traces_mse, rows=[1, 2], cols=[1, 1])\n",
    "    fig_mse.add_traces(run_hist_1b_traces_mse, rows=[1, 2], cols=[1, 1])\n",
    "    fig_mse.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "msa_plot()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](../assets/image-35.jpg)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.confusion_matrix import confusion_matrix\n",
    "\n",
    "y_test_pred = model_1.predict(X_test)\n",
    "\n",
    "c_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "ax = sns.heatmap(\n",
    "    c_matrix,\n",
    "    annot=True,\n",
    "    xticklabels=[\"No Diabetes\", \"Diabetes\"],\n",
    "    yticklabels=[\"No Diabetes\", \"Diabetes\"],\n",
    "    cbar=False,\n",
    "    cmap=\"Blues\",\n",
    "    fmt=\".6g\",\n",
    ")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "plt.show()\n",
    "plt.clf()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Results - ROC Curve\n",
    "y_test_pred_probs = model_1.predict(X_test)\n",
    "FPR, TPR, _ = roc_curve(y_test, y_test_pred_probs)\n",
    "plt.plot(FPR, TPR)\n",
    "plt.plot([0, 1], [0, 1], \"--\", color=\"black\")  # diagonal line\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()\n",
    "plt.clf()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_use_case(model: Model, **kwargs):\n",
    "    def predict(col, data):\n",
    "        data = data.reshape(1, -1)\n",
    "        final_prediction = model.predict(data)\n",
    "        print(f\"col: {col}, final_prediction: \", final_prediction)\n",
    "\n",
    "    if not kwargs:\n",
    "        print(\"Please Enter the Folowing Metrics one at a time\")\n",
    "        a = int(input(\"Enter Metric Pregnancies: \"))\n",
    "        b = int(input(\"Enter Metric Glucose: \"))\n",
    "        c = int(input(\"Enter Metric BloodPressure: \"))\n",
    "        d = int(input(\"Enter Metric SkinThickness: \"))\n",
    "        e = int(input(\"Enter Metric Insulin: \"))\n",
    "        f = float(input(\"Enter Metric BMI: \"))\n",
    "        g = float(input(\"Enter Metric DiabetesPedigreeFunction: \"))\n",
    "        h = int(input(\"Enter Metric Age: \"))\n",
    "        data = np.array([a, b, c, d, e, f, g, h])\n",
    "    else:\n",
    "        for k, v in kwargs.items():\n",
    "            predict(k, np.array(v))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_1.save(\"../models/diabetes_risk_nn.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.saving.save import load_model\n",
    "\n",
    "model = load_model(\"../models/diabetes_risk_nn.h5\")\n",
    "outcome_1 = [6, 148, 72, 35, 0, 33.6, 0.627, 50]\n",
    "outcome_0 = [1, 85, 66, 29, 0, 26.6, 0.351, 31]\n",
    "\n",
    "predict_use_case(model, outcome_1=outcome_1, outcome_0=outcome_0)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
